{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Исходный код этого iPython-блокнота, а также файл с данными и отчёт доступны на GitHub по ссылке\n",
    "https://github.com/dextravaganz/hse-fca-benchmark\n",
    "\n",
    "\n",
    "##  Описание данных\n",
    "\n",
    "В данной работе использовался Mushroom Data Set из UCI Machine Learning Repository. Исходные данные доступны по адресу https://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "Эти данные представляют с собой описание 8124 грибов, для каждого из которых указаны 22 категориальных атрибута, описывающих физические характеристики гриба и метку, показывающую, съедобен данный гриб или нет. \n",
    "\n",
    "Для выполнения работы из исходного массива данных были взяты все наблюдения с меткой съедобности и следующими атрибутами:\n",
    "\n",
    "1. cap-shape\n",
    "2. cap-surface\n",
    "3. cap-color\n",
    "4. bruises\n",
    "5. odor\n",
    "6. gill-attachment\n",
    "7. gill-spacing\n",
    "8. gill-size\n",
    "\n",
    "Рассматриваемые в работе алгоритмы будут сравниваться по  результатам решения задачи бинарной классификации на этих данных - предсказании значения метки съедобности гриба.\n",
    "\n",
    "Поскольку все признаки категориальные и количество категорий небольшое, то  сразу же преобразуем их в бинарные с помощью дамми-переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4208\n",
       "0    3916\n",
       "Name: is_edible, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "src_file = './agaricus-lepiota.data'\n",
    "\n",
    "columns = [\n",
    "    'edible',\n",
    "    'cap-shape',\n",
    "    'cap-surface',\n",
    "    'cap-color',\n",
    "    'bruises',\n",
    "    'odor',\n",
    "    'gill-attachment',\n",
    "    'gill-spacing',\n",
    "    'gill-size',\n",
    "]\n",
    "\n",
    "raw_data = pd.read_csv(src_file, \n",
    "                   header=None,\n",
    "                   usecols=[i for i in range(len(columns))],    \n",
    "                   names=columns)\n",
    "\n",
    "data = pd.get_dummies(raw_data, prefix=columns)\\\n",
    "    .astype(int)\\\n",
    "    .rename(columns={'edible_e' : 'is_edible'})\\\n",
    "    .drop('edible_p', axis=1)\n",
    "\n",
    "target = 'is_edible'\n",
    "\n",
    "data[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, соотношение положительных и отрицательных примеров примерно  одинаковое.\n",
    "\n",
    "## Метод оценки алгоритмов\n",
    "\n",
    "В следующей ячейке реализован  метод, с помощью  которого будет происходить оценка всех алгоритмов в данной работе.\n",
    "\n",
    "В нём алгоритм тестируется на кросс-валидации, посчитанные средние метрики возвращаются в виде DataFrame с одной строкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def evaluate_method(trial_name, classifier, data, target, \n",
    "                    np_convert=False, kf_splits=5):\n",
    "    \"\"\"Common evaluation method for algoritms in this research\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_name : str\n",
    "        Label of current experiment\n",
    "     classifier \n",
    "        Model to be evaluated. \n",
    "        This object must implement 'fit' method\n",
    "    data : DataFrame\n",
    "    target : str\n",
    "        Target feature name\n",
    "    np_convert : bool, default False\n",
    "        Indicates if data should be converted to NumPy \n",
    "        arrays before passing to 'fit' method \n",
    "    kf_splits : int, default 5\n",
    "        KFold number of splits\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        with one row labeled as 'trial_name' \n",
    "        and containig scores in cells\n",
    "    \"\"\"\n",
    "    X = data.drop(target, 1).fillna(0)\n",
    "    Y = data[target]\n",
    "    if np_convert:\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "    \n",
    "    acc, pr, rc, tpr, tnr, fpr, npv, fdr = \\\n",
    "        [np.array([]) for i in xrange(8)]\n",
    "    kf = KFold(n_splits=kf_splits)\n",
    "    for train_ind, test_ind in kf.split(X):\n",
    "        \n",
    "        X_tr = X[train_ind] if np_convert else X.loc[train_ind]\n",
    "        Y_tr = Y[train_ind] if np_convert else Y.loc[train_ind]\n",
    "        \n",
    "        X_test = X[test_ind] if np_convert else X.loc[test_ind]\n",
    "        y_test = Y[test_ind] if np_convert else\\\n",
    "                                    np.array(Y.loc[test_ind])\n",
    "        \n",
    "        current_fold_model = \\\n",
    "            classifier.fit(X_tr, Y_tr)\n",
    "        y_pred = current_fold_model.predict(X_test)\n",
    "        \n",
    "        acc = np.append(acc,accuracy_score(y_test,y_pred))\n",
    "        pr = np.append(pr,precision_score(y_test,y_pred))\n",
    "        rc = np.append(rc,recall_score(y_test,y_pred))\n",
    "        TP = np.sum(y_test * y_pred)\n",
    "        TN = np.sum(y_test + y_pred == 0)\n",
    "        FP = np.sum((y_test  == 0) * (y_pred == 1))\n",
    "        FN = np.sum((y_test  == 1) * (y_pred == 0))\n",
    "        tpr = np.append(tpr,float(TP) / np.sum(y_test == 1))\n",
    "        tnr = np.append(tnr,float(TN) / np.sum(y_test == 0))\n",
    "        fpr = np.append(fpr,float(FP) / ((TP + FN)\\\n",
    "                                      if (TP + FN) !=0 else 1.))\n",
    "\n",
    "        npv = np.append(npv,float(TN) / ((TN + FN)\\\n",
    "                                      if (TN + FN) !=0 else 1.))\n",
    "        fdr = np.append(fdr,float(FP) / ((TP + FP)\\\n",
    "                                      if (TP + FP)!=0 else 1.))\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        np.round(np.array([\n",
    "             [acc.mean(), pr.mean(), rc.mean(), tpr.mean(), \n",
    "              tnr.mean(), fpr.mean(), npv.mean(), fdr.mean()]]),\n",
    "          decimals=4\n",
    "        ),\n",
    "        index = [trial_name],\n",
    "        columns = ['Accuracy', 'Precision', 'Recall', 'TP', 'TN', \n",
    "                   'FP', 'NP', 'FD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Базовое решение\n",
    "В качестве базовой модели, будем использовать GradientBoostingClassifier из scikit-learn с параметрами по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>NP</th>\n",
       "      <th>FD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision  Recall      TP      TN      FP      NP      FD\n",
       "Baseline    0.9892     0.9593  0.9868  0.9868  0.9897  0.0472  0.9968  0.0407"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metrics = evaluate_method('Baseline', \n",
    "                          GradientBoostingClassifier(), \n",
    "                          data, target, \n",
    "                          np_convert=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По всем метрикам, результат градиентного бустинга почти идеален, однако недостатком этого алгоритма можно считать плохую интерпретируемость.\n",
    "\n",
    "Посмотрим, как с этой же задачей справятся методы упорядоченных множеств и анализа формальных понятий, которые этого недостатка лишены.\n",
    "\n",
    "## 2. ДСМ-Метод \n",
    "\n",
    "Далее представлена моя реализация алгортима поиска формальных понятий Close by One с возможностью ограничить поиск формальных понятий по размеру содержания или по количеству найденных формальных понятий.\n",
    "\n",
    "Этот алгоритм будет использоваться для порождения формальных понятий в контекстах положительных и отрицательных примеров. Представленный далее ДСМ-классификатор будет использовать полученные формальные понятия как гипотезы для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FormalContext:\n",
    "    \"\"\":param ctx - Pandas DataFrame representing formal context\"\"\"\n",
    "    def __init__(self, ctx):\n",
    "        self.ctx = ctx\n",
    "        self.M = list(ctx.columns)\n",
    "        self.G = list(ctx.index)\n",
    "\n",
    "    def get_g(self, attributes):\n",
    "        ind = self.ctx[attributes].all(1)\n",
    "        return list(self.ctx[ind].index)\n",
    "\n",
    "    def get_m(self, objects):\n",
    "        ind = self.ctx.loc[objects].all()\n",
    "        return list(self.ctx.columns[ind])\n",
    "            \n",
    "def close_by_one(ctx, max_fc=-1, max_intent=-1):\n",
    "    M = sorted(ctx.M)\n",
    "    if max_intent < 0:\n",
    "        max_intent = len(M)\n",
    "    if max_fc < 0:\n",
    "        max_fc = 2**min(len(M), len(ctx.G))\n",
    "    formal_concepts = []\n",
    "    if ctx.get_m(ctx.get_g([])) == [] and max_fc > 0:\n",
    "        formal_concepts.append(([], ctx.get_g([])))\n",
    "    def close_by_one_inner(candidate_prefix):\n",
    "        last_ind = M.index(candidate_prefix[-1]) \\\n",
    "            if len(candidate_prefix) > 0 else 1\n",
    "        for i in xrange(last_ind + 1, len(M)):\n",
    "            next = candidate_prefix + [M[i]]\n",
    "            while not set(ctx.get_m(ctx.get_g(next)))==\\\n",
    "                      set(next) and\\\n",
    "                  i < len(M) - 1: \n",
    "                i += 1\n",
    "                next.append(M[i])\n",
    "            if set(ctx.get_m(ctx.get_g(next))) == set(next) and\\\n",
    "                len(next) <= max_intent and\\\n",
    "                len(formal_concepts) < max_fc:\n",
    "                formal_concepts.append((next, ctx.get_g(next)))\n",
    "                close_by_one_inner(next)\n",
    "            else:\n",
    "                pass\n",
    "    close_by_one_inner([])\n",
    "    \n",
    "    return formal_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена моя совбственная реализация ДСМ классификатора.\n",
    "Он предоставляет возможность задать результат классификации по умолчанию, который будет использоваться в спорных ситуациях, использовать ли нормировку голосов на количество гипотез, а также максимальное допустимое количество контр-примеров, при которых гипотеза классификации принимается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class JSMClassifier:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 unclassified_label=0,\n",
    "                 vote_adjustment='None',\n",
    "                 max_positive_counter_exmpls=0,\n",
    "                 max_negative_counter_exmpls=0,\n",
    "                 max_positive_fc=-1, \n",
    "                 max_negative_fc=-1,\n",
    "                 max_positive_intent=-1,\n",
    "                 max_negative_intent=-1,\n",
    "                 debug_output=False):\n",
    "        self.unclassified_label = unclassified_label\n",
    "        self.max_positive_counter_exmpls = max_positive_counter_exmpls\n",
    "        self.max_negative_counter_exmpls = max_negative_counter_exmpls\n",
    "        if not vote_adjustment in ('None', 'HypothesisCount'):\n",
    "            raise ValueError('Unsupperted vote_adjustment')\n",
    "        self.vote_adjustment = vote_adjustment\n",
    "        self._max_positive_fc=max_positive_fc\n",
    "        self._max_negative_fc=max_negative_fc\n",
    "        self._max_positive_intent=max_positive_intent\n",
    "        self._max_negative_intent=max_negative_intent\n",
    "        self._debug_output = debug_output\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        if self._debug_output:\n",
    "            print('-- fit(X,Y) start --')\n",
    "        \n",
    "        self._positive_ctx = FormalContext(X[Y == 1.])\n",
    "        self._negative_ctx = FormalContext(X[Y == 0.])\n",
    "        \n",
    "        positive_fc = \\\n",
    "            close_by_one(self._positive_ctx, \n",
    "                         max_fc=self._max_positive_fc,\n",
    "                         max_intent=self._max_positive_intent)\n",
    "        if self._debug_output:\n",
    "            print('Positive concepts count:' +\\\n",
    "                  str(len(positive_fc)))\n",
    "        self._positive_hypothesis = []\n",
    "        for (attributes, _) in positive_fc:\n",
    "            if len(self._negative_ctx.get_g(attributes)) <=\\\n",
    "                   self.max_negative_counter_exmpls:\n",
    "                self._positive_hypothesis.append(attributes)\n",
    "        \n",
    "        negative_fc = \\\n",
    "            close_by_one(self._negative_ctx, \n",
    "                         max_fc=self._max_negative_fc,\n",
    "                         max_intent=self._max_negative_intent)\n",
    "        if self._debug_output:\n",
    "            print('Negative concepts count:' +\\\n",
    "                  str(len(negative_fc)))\n",
    "        self._negative_hypothesis = []\n",
    "        for (attributes, _) in negative_fc:\n",
    "            if len(self._positive_ctx.get_g(attributes)) <= \\\n",
    "                   self.max_positive_counter_exmpls:\n",
    "                self._negative_hypothesis.append(attributes)\n",
    "        \n",
    "        if self._debug_output:\n",
    "            print('Total positive hypothesis:' + \\\n",
    "                  str(len(self._positive_hypothesis)))\n",
    "            print('Total neagative hypothesis:' + \\\n",
    "                  str(len(self._negative_hypothesis)))\n",
    "        if self._debug_output:\n",
    "            print('-- fit(X,Y) end --')\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, g):         \n",
    "        positive_votes = \\\n",
    "            pd.DataFrame(np.zeros(len(g.index)), \n",
    "                         index=g.index,columns=['sum'])\n",
    "        for hypo in self._positive_hypothesis:\n",
    "            positive_votes['sum'] += \\\n",
    "                (g[hypo].sum(1)==len(hypo)).astype(int)\n",
    "        \n",
    "        positive_adj = len(self._positive_hypothesis) \\\n",
    "            if self.vote_adjustment=='HypothesisCount' and\\\n",
    "                len(self._positive_hypothesis) > 0 else 1. \n",
    "        positive_votes['sum'] = \\\n",
    "            positive_votes['sum'].astype(float) / positive_adj\n",
    "        \n",
    "        \n",
    "        negative_votes = \\\n",
    "            pd.DataFrame(np.zeros(len(g.index)), \n",
    "                         index=g.index, columns=['sum'])\n",
    "        for hypo in self._negative_hypothesis:\n",
    "            negative_votes['sum'] += \\\n",
    "                (g[hypo].sum(1)==len(hypo)).astype(int)\n",
    "        \n",
    "        negative_adj = len(self._negative_hypothesis) \\\n",
    "            if self.vote_adjustment=='HypothesisCount' and\\\n",
    "                len(self._negative_hypothesis) > 0 else 1.\n",
    "        negative_votes['sum'] = \\\n",
    "            negative_votes['sum'].astype(float) / negative_adj\n",
    "        \n",
    "        if self.unclassified_label == 1:\n",
    "            pred = positive_votes['sum'] >= negative_votes['sum']\n",
    "        else:\n",
    "            pred = positive_votes['sum'] > negative_votes['sum']\n",
    "                  \n",
    "        return pred.values.T.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как ДСМ классификатор решает нашу задачу с параметрами по умаолчанию. \n",
    "Параметры по умолчанию предполагают, что в качестве гипотез будт проверяться все существующие в контекстах формальные понятия, результат голосования никак не будет нормироваться, а все принимаемые гипотезы должны быть строгими, то есть не допускать контрпримеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- fit(X,Y) start --\n",
      "Positive concepts count:115\n",
      "Negative concepts count:55\n",
      "Total positive hypothesis:17\n",
      "Total neagative hypothesis:3\n",
      "-- fit(X,Y) end --\n",
      "-- fit(X,Y) start --\n",
      "Positive concepts count:130\n",
      "Negative concepts count:55\n",
      "Total positive hypothesis:21\n",
      "Total neagative hypothesis:3\n",
      "-- fit(X,Y) end --\n",
      "-- fit(X,Y) start --\n",
      "Positive concepts count:130\n",
      "Negative concepts count:55\n",
      "Total positive hypothesis:21\n",
      "Total neagative hypothesis:3\n",
      "-- fit(X,Y) end --\n",
      "-- fit(X,Y) start --\n",
      "Positive concepts count:129\n",
      "Negative concepts count:40\n",
      "Total positive hypothesis:33\n",
      "Total neagative hypothesis:3\n",
      "-- fit(X,Y) end --\n",
      "-- fit(X,Y) start --\n",
      "Positive concepts count:80\n",
      "Negative concepts count:9\n",
      "Total positive hypothesis:18\n",
      "Total neagative hypothesis:1\n",
      "-- fit(X,Y) end --\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>NP</th>\n",
       "      <th>FD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (strict)</th>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy  Precision  Recall      TP      TN      FP      NP  \\\n",
       "Baseline        0.9892     0.9593  0.9868  0.9868  0.9897  0.0472  0.9968   \n",
       "JSM (strict)    0.7596     0.9764  0.5176  0.5176  0.9961  0.0134  0.6111   \n",
       "\n",
       "                  FD  \n",
       "Baseline      0.0407  \n",
       "JSM (strict)  0.0236  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = metrics.append(\n",
    "    evaluate_method('JSM (strict)', \n",
    "                    JSMClassifier(debug_output=True), \n",
    "                    data, target, \n",
    "                    np_convert=False))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты неплохие. ДСМ метод с параметрами по умолчанию справляется с задачей явно лучше, чем случайное угадывание, однако до качества градиентного  бустинга пока не дотягивает.\n",
    "\n",
    "Можно заметить, что при высоком  True Negative  rate, очень низкий показатель True Positive, то есть данный классификатор часто определяет положительные как отрицательные.\n",
    "\n",
    "В контексте выбора грибов это, может быть, и хорошо: лучше не съесть ядовитый гриб, чем  выкинуть съедобный, однако  от этого смещения страдает общая точность классификации,\n",
    "\n",
    "Попробуем улучшить показатели.\n",
    "Судя по выводу отладки, в большинстве случаев, отрицательных гипотез больше, чем положительных, от этого и смещение.\n",
    "Попробуем  внести следующие изменения в настройки:\n",
    "1. Включим нормирование на количество гипотез, чтобы решение принималось процентным большиством, а не абсолютным\n",
    "2. Попробуем получить большее колчиство положительных гипотез, разрешив принимать положительную гипотезу с небольшим количеством контрпримеров, попробуем  со значениями 3, 5 и 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>NP</th>\n",
       "      <th>FD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (strict)</th>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (strict, adj)</th>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 3)</th>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 5)</th>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 10)</th>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>0.0605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Precision  Recall      TP      TN      FP  \\\n",
       "Baseline             0.9892     0.9593  0.9868  0.9868  0.9897  0.0472   \n",
       "JSM (strict)         0.7596     0.9764  0.5176  0.5176  0.9961  0.0134   \n",
       "JSM (strict, adj)    0.7596     0.9764  0.5176  0.5176  0.9961  0.0134   \n",
       "JSM (soft+, 3)       0.7752     0.9503  0.5861  0.5861  0.9894  0.0460   \n",
       "JSM (soft+, 5)       0.8010     0.9424  0.6531  0.6531  0.9845  0.0700   \n",
       "JSM (soft+, 10)      0.8027     0.9395  0.6571  0.6571  0.9835  0.0750   \n",
       "\n",
       "                       NP      FD  \n",
       "Baseline           0.9968  0.0407  \n",
       "JSM (strict)       0.6111  0.0236  \n",
       "JSM (strict, adj)  0.6111  0.0236  \n",
       "JSM (soft+, 3)     0.6242  0.0497  \n",
       "JSM (soft+, 5)     0.6458  0.0576  \n",
       "JSM (soft+, 10)    0.6473  0.0605  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = metrics.append(\n",
    "    evaluate_method('JSM (strict, adj)', \n",
    "                    JSMClassifier(\n",
    "                        vote_adjustment='HypothesisCount'), \n",
    "                    data, target, \n",
    "                    np_convert=False))\n",
    "metrics = metrics.append(\n",
    "    evaluate_method('JSM (soft+, 3)', \n",
    "                    JSMClassifier(\n",
    "                        max_negative_counter_exmpls=3), \n",
    "                    data, target, \n",
    "                    np_convert=False))\n",
    "metrics = metrics.append(\n",
    "    evaluate_method('JSM (soft+, 5)', \n",
    "                    JSMClassifier(\n",
    "                        max_negative_counter_exmpls=5), \n",
    "                    data, target, \n",
    "                    np_convert=False))\n",
    "metrics = metrics.append(\n",
    "    evaluate_method('JSM (soft+, 10)', \n",
    "                    JSMClassifier(\n",
    "                        max_negative_counter_exmpls=10), \n",
    "                    data, target, \n",
    "                    np_convert=False))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормирование по колчиству гипотез не изменило ситуацию, а вот смягчение положительных гипотез дало прирост точности. \n",
    "\n",
    "Однако, как можно заметить, наибольший прирост дают гипотезы, у которых не больше 5 контрпримеров в отрицательном контексте, а гипотезы, у которых от 5 до 10 контрпримеров, оказывают несущественное влияние.\n",
    "\n",
    "## 3. Ленивый алгоритм\n",
    "Анализ ошибок классификации и настройка ДСМ метода позволяет приблизиться к качеству градиентного бустинга, однако у такого метода есть существенный недостаток - при обучении, для построения гипотез нужно найти формальные понятия, что в худшем случае делается за экспоненциальное время. \n",
    "\n",
    "Поэтому далее мы рассмотрим алгоритм ленивой классификации, в котором не требуется находить формальные понятия. (Из корня репозитория lazyfca15 с незначительными доработками)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LazyClassifier:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 unclassified_label=0,\n",
    "                 debug_output=False):\n",
    "        self.unclassified_label = unclassified_label\n",
    "        self._debug_output = debug_output\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self._positive = X[Y == 1]\n",
    "        self._negative = X[Y == 0]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        unclassified = 0\n",
    "        for test_obj in X_test:\n",
    "            pos = np.sum(test_obj == self._positive) / float(len(self._positive))\n",
    "            neg = np.sum(test_obj == self._negative) / float(len(self._negative))\n",
    "            if pos > neg:\n",
    "                y_pred.append(1)\n",
    "            elif pos < neg:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                unclassified+=1\n",
    "                y_pred.append(self.unclassified_label)\n",
    "        if self._debug_output:\n",
    "            print(str(unclassified) + ' objects were unclassified')\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>NP</th>\n",
       "      <th>FD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (strict)</th>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (strict, adj)</th>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 3)</th>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 5)</th>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JSM (soft+, 10)</th>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>0.0605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lazy</th>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.2855</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.1623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Precision  Recall      TP      TN      FP  \\\n",
       "Baseline             0.9892     0.9593  0.9868  0.9868  0.9897  0.0472   \n",
       "JSM (strict)         0.7596     0.9764  0.5176  0.5176  0.9961  0.0134   \n",
       "JSM (strict, adj)    0.7596     0.9764  0.5176  0.5176  0.9961  0.0134   \n",
       "JSM (soft+, 3)       0.7752     0.9503  0.5861  0.5861  0.9894  0.0460   \n",
       "JSM (soft+, 5)       0.8010     0.9424  0.6531  0.6531  0.9845  0.0700   \n",
       "JSM (soft+, 10)      0.8027     0.9395  0.6571  0.6571  0.9835  0.0750   \n",
       "Lazy                 0.9189     0.8377  0.9290  0.9290  0.9268  0.2855   \n",
       "\n",
       "                       NP      FD  \n",
       "Baseline           0.9968  0.0407  \n",
       "JSM (strict)       0.6111  0.0236  \n",
       "JSM (strict, adj)  0.6111  0.0236  \n",
       "JSM (soft+, 3)     0.6242  0.0497  \n",
       "JSM (soft+, 5)     0.6458  0.0576  \n",
       "JSM (soft+, 10)    0.6473  0.0605  \n",
       "Lazy               0.9074  0.1623  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = metrics.append(\n",
    "    evaluate_method('Lazy', \n",
    "                    LazyClassifier(), \n",
    "                    data, target, \n",
    "                    np_convert=True))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Простой метод ленивой классификации смог значительно превзойти ДСМ без всякой настройки.\n",
    "\n",
    "В заключение можно сказать, что построение предсказетельных моделей - долгий и кропотливый процесс, требующий много итераций. Всегда лучше начинать с простого алгоритма, с интерпретируемыми результатами. Высока вероятность, что при минимальной настройке он сможет выполнять поставленую задачу с адекватным качеством. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
